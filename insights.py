# -*- coding: utf-8 -*-
"""insights.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xfqLvtfWLFUKOJ6XZ5EY6CBletnop7Is
"""

import numpy as np
import pandas as pd

def top_correlations(df, thresh=0.7):
    num_df = df.select_dtypes(include=[np.number])
    corr = num_df.corr().abs()
    pairs = []
    for i in range(len(corr.columns)):
        for j in range(i+1, len(corr.columns)):
            c1 = corr.columns[i]
            c2 = corr.columns[j]
            val = corr.iloc[i, j]
            if val >= thresh:
                pairs.append((c1, c2, float(val)))
    return pairs

def distribution_insights(df):
    """
    For numeric columns, returns simple distribution insights (skew, presence of outliers by IQR).
    """
    num_df = df.select_dtypes(include=[np.number])
    insights = {}
    for c in num_df.columns:
        series = num_df[c].dropna()
        if series.empty:
            continue
        skew = float(series.skew())
        q1, q3 = np.percentile(series, [25, 75])
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        outliers = series[(series < lower) | (series > upper)]
        insights[c] = {
            "skew": skew,
            "n_outliers": int(outliers.count()),
            "median": float(series.median()),
            "mean": float(series.mean()),
        }
    return insights

def generate_insights_text(df):
    """
    Compose a human-readable summary (rule-based).
    """
    parts = []
    # Basic shape
    parts.append(f"The dataset has {df.shape[0]} rows and {df.shape[1]} columns.")

    # Missingness
    missing = df.isna().sum()
    missing = missing[missing > 0].sort_values(ascending=False)
    if not missing.empty:
        parts.append("Columns with missing values:")
        for col, cnt in missing.items():
            parts.append(f"- {col}: {int(cnt)} missing values")
    else:
        parts.append("No missing values detected.")

    # Correlations
    corr_pairs = top_correlations(df, thresh=0.7)
    if corr_pairs:
        parts.append("Strong linear relationships (|corr| >= 0.7) found between:")
        for c1, c2, val in corr_pairs:
            parts.append(f"- {c1} and {c2} (corr = {val:.2f})")
    else:
        parts.append("No very strong linear correlations (|corr| >= 0.7) found among numeric variables.")

    # Distribution observations
    dist = distribution_insights(df)
    for col, stats in dist.items():
        s = stats["skew"]
        outcount = stats["n_outliers"]
        if abs(s) > 1.0:
            skew_text = "highly skewed"
        elif abs(s) > 0.5:
            skew_text = "moderately skewed"
        else:
            skew_text = "approximately symmetric"
        parts.append(f"Column '{col}' is {skew_text} (skew={s:.2f}), median={stats['median']:.2f}, mean={stats['mean']:.2f}, outliers detected={outcount}.")

    text = "\n".join(parts)
    print("[insights] Generated textual insights")
    return text

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", default="../data/sample.csv")
    args = parser.parse_args()
    import data_loader, preprocess
    df = data_loader.load_data(args.input)
    df = preprocess.preprocess_data(df)
    print(generate_insights_text(df))